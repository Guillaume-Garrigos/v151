---
title: " Adaptive Importance Sampling meets Mirror Descent : a Bias-variance Tradeoff "
abstract: " Adaptive importance sampling is a widely spread Monte Carlo technique
  that uses a re-weighting strategy to iteratively estimate the so-called target distribution.
  A major drawback of adaptive importance sampling is the large variance of the weights
  which is known to badly impact the accuracy of the estimates. This paper investigates
  a regularization strategy whose basic principle is to raise the importance weights
  at a certain power. This regularization parameter, that might evolve between zero
  and one during the algorithm, is shown (i) to balance between the bias and the variance
  and (ii) to be connected to the mirror descent framework. Using a kernel density
  estimate to build the sampling policy, the uniform convergence is established under
  mild conditions. Finally, several practical ways to choose the regularization parameter
  are discussed and the benefits of the proposed approach are illustrated empirically. "
software: " https://github.com/akorba/Safe_And_Regularized_Importance_Sampling "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: korba22a
month: 0
tex_title: " Adaptive Importance Sampling meets Mirror Descent : a Bias-variance Tradeoff "
firstpage: 11503
lastpage: 11527
page: 11503-11527
order: 11503
cycles: false
bibtex_author: Korba, Anna and Portier, Fran\c{c}ois
author:
- given: Anna
  family: Korba
- given: Fran√ßois
  family: Portier
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/korba22a/korba22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
