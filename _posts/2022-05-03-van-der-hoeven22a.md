---
title: " Nonstochastic Bandits and Experts with Arm-Dependent Delays "
abstract: " We study nonstochastic bandits and experts in a delayed setting where
  delays depend on both time and arms. While the setting in which delays only depend
  on time has been extensively studied, the arm-dependent delay setting better captures
  real-world applications at the cost of introducing new technical challenges. In
  the full information (experts) setting, we design an algorithm with a first-order
  regret bound that reveals an interesting trade-off between delays and losses. We
  prove a similar first-order regret bound also for the bandit setting, when the learner
  is allowed to observe how many losses are missing. Our bounds are the first in the
  delayed setting that only depend on the losses and delays of the best arm. In the
  bandit setting, when no information other than the losses is observed, we still
  manage to prove a regret bound for bandits through a modification to the algorithm
  of Zimmert and Seldin (2020). Our analyses hinge on a novel bound on the drift,
  measuring how much better an algorithm can perform when given a look-ahead of one
  round. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: van-der-hoeven22a
month: 0
tex_title: " Nonstochastic Bandits and Experts with Arm-Dependent Delays "
firstpage: 2022
lastpage: 2044
page: 2022-2044
order: 2022
cycles: false
bibtex_author: Van Der Hoeven, Dirk and Cesa-Bianchi, Nicol\`o
author:
- given: Dirk
  family: Van Der Hoeven
- given: Nicol√≤
  family: Cesa-Bianchi
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/van-der-hoeven22a/van-der-hoeven22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
