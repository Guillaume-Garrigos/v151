---
title: " Random Effect Bandits "
abstract: " This paper studies regret minimization in a multi-armed bandit. It is
  well known that side information, such as the prior distribution of arm means in
  Thompson sampling, can improve the statistical efficiency of the bandit algorithm.
  While the prior is a blessing when correctly specified, it is a curse when misspecified.
  To address this issue, we introduce the assumption of a random-effect model to bandits.
  In this model, the mean arm rewards are drawn independently from an unknown distribution,
  which we estimate. We derive a random-effect estimator of the arm means, analyze
  its uncertainty, and design a UCB algorithm ReUCB that uses it. We analyze ReUCB
  and derive an upper bound on its n-round Bayes regret, which improves upon not using
  the random-effect structure. Our experiments show that ReUCB can outperform Thompson
  sampling, without knowing the prior distribution of arm means. "
software: " https://github.com/rong-zhu/random_effect_bandits "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu22b
month: 0
tex_title: " Random Effect Bandits "
firstpage: 3091
lastpage: 3107
page: 3091-3107
order: 3091
cycles: false
bibtex_author: Zhu, Rong and Kveton, Branislav
author:
- given: Rong
  family: Zhu
- given: Branislav
  family: Kveton
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/zhu22b/zhu22b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
