---
title: " Online Learning for Unknown Partially Observable MDPs "
abstract: " Solving Partially Observable Markov Decision Processes (POMDPs) is hard.
  Learning optimal controllers for POMDPs when the model is unknown is harder. Online
  learning of optimal controllers for unknown POMDPs, which requires efficient learning
  using regret-minimizing algorithms that effectively tradeoff exploration and exploitation,
  is even harder, and no solution exists currently. In this paper, we consider infinite-horizon
  average-cost POMDPs with unknown transition model, though a known observation model.
  We propose a natural posterior sampling-based reinforcement learning algorithm (PSRL-POMDP)
  and show that it achieves a regret bound of $O(\\log T)$, where $T$ is the time
  horizon, when the parameter set is finite. In the general case (continuous parameter
  set), we show that the algorithm achieves $O(T^{2/3})$ regret under two technical
  assumptions. To the best of our knowledge, this is the first online RL algorithm
  for POMDPs and has sub-linear regret. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jafarnia-jahromi22a
month: 0
tex_title: " Online Learning for Unknown Partially Observable MDPs "
firstpage: 1712
lastpage: 1732
page: 1712-1732
order: 1712
cycles: false
bibtex_author: Jafarnia Jahromi, Mehdi and Jain, Rahul and Nayyar, Ashutosh
author:
- given: Mehdi
  family: Jafarnia Jahromi
- given: Rahul
  family: Jain
- given: Ashutosh
  family: Nayyar
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/jafarnia-jahromi22a/jafarnia-jahromi22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
