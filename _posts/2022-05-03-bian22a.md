---
title: " Maillard Sampling: Boltzmann Exploration Done Optimally "
abstract: " The PhD thesis of Maillard (2013) presents a rather obscure algorithm
  for the $K$-armed bandit problem. This less-known algorithm, which we call Maillard
  sampling (MS), computes the probability of choosing each arm in a closed form, which
  is not true for Thompson sampling, a widely-adopted bandit algorithm in the industry.
  This means that the bandit-logged data from running MS can be readily used for counterfactual
  evaluation, unlike Thompson sampling. Motivated by such merit, we revisit MS and
  perform an improved analysis to show that it achieves both the asymptotical optimality
  and $\\sqrt{KT\\log{T}}$ minimax regret bound where $T$ is the time horizon, which
  matches the known bounds for asymptotically optimal UCB. We then propose a variant
  of MS called MS$^+$ that improves its minimax bound to $\\sqrt{KT\\log{K}}$. MS$^+$
  can also be tuned to be aggressive (i.e., less exploration) without losing the asymptotic
  optimality, a unique feature unavailable from existing bandit algorithms. Our numerical
  evaluation shows the effectiveness of MS$^+$. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bian22a
month: 0
tex_title: " Maillard Sampling: Boltzmann Exploration Done Optimally "
firstpage: 54
lastpage: 72
page: 54-72
order: 54
cycles: false
bibtex_author: Bian, Jie and Jun, Kwang-Sung
author:
- given: Jie
  family: Bian
- given: Kwang-Sung
  family: Jun
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/bian22a/bian22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
