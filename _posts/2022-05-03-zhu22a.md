---
title: " Safe Optimal Design with Applications in Off-Policy Learning "
abstract: " Motivated by practical needs in online experimentation and off-policy
  learning, we study the problem of safe optimal design, where we develop a data logging
  policy that efficiently explores while achieving competitive rewards with a baseline
  production policy. We first show, perhaps surprisingly, that a common practice of
  mixing the production policy with uniform exploration, despite being safe, is sub-optimal
  in maximizing information gain. Then we propose a safe optimal logging policy for
  the case when no side information about the actionsâ€™ expected rewards is available.
  We improve upon this design by considering side information and also extend both
  approaches to a large number of actions with a linear reward model. We analyze how
  our data logging policies impact errors in off-policy learning. Finally, we empirically
  validate the benefit of our designs by conducting extensive experiments. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu22a
month: 0
tex_title: " Safe Optimal Design with Applications in Off-Policy Learning "
firstpage: 2436
lastpage: 2447
page: 2436-2447
order: 2436
cycles: false
bibtex_author: Zhu, Ruihao and Kveton, Branislav
author:
- given: Ruihao
  family: Zhu
- given: Branislav
  family: Kveton
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/zhu22a/zhu22a.pdf
extras:
- label: Supplementary ZIP
  link: https://proceedings.mlr.press/v151/zhu22a/zhu22a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
