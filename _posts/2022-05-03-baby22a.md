---
title: " Optimal Dynamic Regret in Proper Online Learning with Strongly Convex Losses
  and Beyond "
abstract: " We study the framework of <em>universal dynamic regret</em> minimization
  with <em>strongly convex</em> losses. We answer an open problem in Baby and Wang
  2021 by showing that in a <em>proper learning</em> setup, Strongly Adaptive algorithms
  can achieve the near optimal dynamic regret of $\\tilde O(d^{1/3} n^{1/3}\\text{TV}[u_{1:n}]^{2/3}
  \\vee d)$ against any comparator sequence $u_1,\\ldots,u_n$ <em>simultaneously</em>,
  where $n$ is the time horizon and $\\text{TV}[u_{1:n}]$ is the Total Variation of
  comparator. These results are facilitated by exploiting a number of <em>new</em>
  structures imposed by the KKT conditions that were not considered in Baby and Wang
  2021 which also lead to other improvements over their results such as: (a) handling
  non-smooth losses and (b) improving the dimension dependence on regret. Further,
  we also derive near optimal dynamic regret rates for the special case of proper
  online learning with exp-concave losses and an $L_\\infty$ constrained decision
  set. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: baby22a
month: 0
tex_title: " Optimal Dynamic Regret in Proper Online Learning with Strongly Convex
  Losses and Beyond "
firstpage: 1805
lastpage: 1845
page: 1805-1845
order: 1805
cycles: false
bibtex_author: Baby, Dheeraj and Wang, Yu-Xiang
author:
- given: Dheeraj
  family: Baby
- given: Yu-Xiang
  family: Wang
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/baby22a/baby22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
