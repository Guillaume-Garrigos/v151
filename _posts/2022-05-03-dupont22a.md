---
title: " Generative Models as Distributions of Functions "
abstract: " Generative models are typically trained on grid-like data such as images.
  As a result, the size of these models usually scales directly with the underlying
  grid resolution. In this paper, we abandon discretized grids and instead parameterize
  individual data points by continuous functions. We then build generative models
  by learning distributions over such functions. By treating data points as functions,
  we can abstract away from the specific type of data we train on and construct models
  that are agnostic to discretization. To train our model, we use an adversarial approach
  with a discriminator that acts on continuous signals. Through experiments on a wide
  variety of data modalities including images, 3D shapes and climate data, we demonstrate
  that our model can learn rich distributions of functions independently of data type
  and resolution. "
software: " https://github.com/EmilienDupont/neural-function-distributions "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dupont22a
month: 0
tex_title: " Generative Models as Distributions of Functions "
firstpage: 2989
lastpage: 3015
page: 2989-3015
order: 2989
cycles: false
bibtex_author: Dupont, Emilien and Whye Teh, Yee and Doucet, Arnaud
author:
- given: Emilien
  family: Dupont
- given: Yee
  family: Whye Teh
- given: Arnaud
  family: Doucet
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/dupont22a/dupont22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
