---
title: " Rapid Convergence of Informed Importance Tempering "
abstract: " Informed Markov chain Monte Carlo (MCMC) methods have been proposed as
  scalable solutions to Bayesian posterior computation on high-dimensional discrete
  state spaces, but theoretical results about their convergence behavior in general
  settings are lacking. In this article, we propose a class of MCMC schemes called
  informed importance tempering (IIT), which combine importance sampling and informed
  local proposals, and derive generally applicable spectral gap bounds for IIT estimators.
  Our theory shows that IIT samplers have remarkable scalability when the target posterior
  distribution concentrates on a small set. Further, both our theory and numerical
  experiments demonstrate that the informed proposal should be chosen with caution:
  the performance may be very sensitive to the shape of the target distribution. We
  find that the “square-root proposal weighting” scheme tends to perform well in most
  settings. "
software: " https://github.com/zhouquan34/IIT "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhou22e
month: 0
tex_title: " Rapid Convergence of Informed Importance Tempering "
firstpage: 10939
lastpage: 10965
page: 10939-10965
order: 10939
cycles: false
bibtex_author: Zhou, Quan and Smith, Aaron
author:
- given: Quan
  family: Zhou
- given: Aaron
  family: Smith
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/zhou22e/zhou22e.pdf
extras:
- label: Supplementary ZIP
  link: https://proceedings.mlr.press/v151/zhou22e/zhou22e-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
