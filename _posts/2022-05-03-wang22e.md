---
title: " Communication-Compressed Adaptive Gradient Method for Distributed Nonconvex
  Optimization "
abstract: " Due to the explosion in the size of the training datasets, distributed
  learning has received growing interest in recent years. One of the major bottlenecks
  is the large communication cost between the central server and the local workers.
  While error feedback compression has been proven to be successful in reducing communication
  costs with stochastic gradient descent (SGD), there are much fewer attempts in building
  communication-efficient adaptive gradient methods with provable guarantees, which
  are widely used in training large-scale machine learning models. In this paper,
  we propose a new communication-compressed AMSGrad for distributed nonconvex optimization
  problem, which is provably efficient. Our proposed distributed learning framework
  features an effective gradient compression strategy and a worker-side model update
  design. We prove that the proposed communication-efficient distributed adaptive
  gradient method converges to the first-order stationary point with the same iteration
  complexity as uncompressed vanilla AMSGrad in the stochastic nonconvex optimization
  setting. Experiments on various benchmarks back up our theory. "
software: " https://github.com/jinghuichen/CD-Adam "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang22e
month: 0
tex_title: " Communication-Compressed Adaptive Gradient Method for Distributed Nonconvex
  Optimization "
firstpage: 6292
lastpage: 6320
page: 6292-6320
order: 6292
cycles: false
bibtex_author: Wang, Yujia and Lin, Lu and Chen, Jinghui
author:
- given: Yujia
  family: Wang
- given: Lu
  family: Lin
- given: Jinghui
  family: Chen
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/wang22e/wang22e.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
