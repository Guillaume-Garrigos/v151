---
title: " Sinkformers: Transformers with Doubly Stochastic Attention "
abstract: " Attention based models such as Transformers involve pairwise interactions
  between data points, modeled with a learnable attention matrix. Importantly, this
  attention matrix is normalized with the SoftMax operator, which makes it row-wise
  stochastic. In this paper, we propose instead to use Sinkhorn’s algorithm to make
  attention matrices doubly stochastic. We call the resulting model a Sinkformer.
  We show that the row-wise stochastic attention matrices in classical Transformers
  get close to doubly stochastic matrices as the number of epochs increases, justifying
  the use of Sinkhorn normalization as an informative prior. On the theoretical side,
  we show that, unlike the SoftMax operation, this normalization makes it possible
  to understand the iterations of self-attention modules as a discretized gradient-flow
  for the Wasserstein metric. We also show in the infinite number of samples limit
  that, when rescaling both attention matrices and depth, Sinkformers operate a heat
  diffusion. On the experimental side, we show that Sinkformers enhance model accuracy
  in vision and natural language processing tasks. In particular, on 3D shapes classification,
  Sinkformers lead to a significant improvement. "
software: " https://github.com/michaelsdr/sinkformers "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sander22a
month: 0
tex_title: " Sinkformers: Transformers with Doubly Stochastic Attention "
firstpage: 3515
lastpage: 3530
page: 3515-3530
order: 3515
cycles: false
bibtex_author: Sander, Michael E. and Ablin, Pierre and Blondel, Mathieu and Peyr\'e,
  Gabriel
author:
- given: Michael E.
  family: Sander
- given: Pierre
  family: Ablin
- given: Mathieu
  family: Blondel
- given: Gabriel
  family: Peyré
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/sander22a/sander22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
