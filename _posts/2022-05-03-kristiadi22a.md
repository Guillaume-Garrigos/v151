---
title: " Being a Bit Frequentist Improves Bayesian Neural Networks "
abstract: " Despite their compelling theoretical properties, Bayesian neural networks
  (BNNs) tend to perform worse than frequentist methods in classification-based uncertainty
  quantification (UQ) tasks such as out-of-distribution (OOD) detection. In this paper,
  based on empirical findings in prior works, we hypothesize that this issue is because
  even recent Bayesian methods have never considered OOD data in their training processes,
  even though this “OOD training” technique is an integral part of state-of-the-art
  frequentist UQ methods. To validate this, we treat OOD data as a first-class citizen
  in BNN training by exploring four different ways of incorporating OOD data into
  Bayesian inference. We show in extensive experiments that OOD-trained BNNs are competitive
  to recent frequentist baselines. This work thus provides strong baselines for future
  work in Bayesian UQ. "
software: " https://github.com/wiseodd/bayesian_ood_training "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kristiadi22a
month: 0
tex_title: " Being a Bit Frequentist Improves Bayesian Neural Networks "
firstpage: 529
lastpage: 545
page: 529-545
order: 529
cycles: false
bibtex_author: Kristiadi, Agustinus and Hein, Matthias and Hennig, Philipp
author:
- given: Agustinus
  family: Kristiadi
- given: Matthias
  family: Hein
- given: Philipp
  family: Hennig
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/kristiadi22a/kristiadi22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
