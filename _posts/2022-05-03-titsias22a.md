---
title: " Double Control Variates for Gradient Estimation in Discrete Latent Variable
  Models "
abstract: " Stochastic gradient-based optimisation for discrete latent variable models
  is challenging due to the high variance of gradients. We introduce a variance reduction
  technique for score function estimators that makes use of double control variates.
  These control variates act on top of a main control variate, and try to further
  reduce the variance of the overall estimator. We develop a double control variate
  for the REINFORCE leave-one-out estimator using Taylor expansions. For training
  discrete latent variable models, such as variational autoencoders with binary latent
  variables, our approach adds no extra computational cost compared to standard training
  with the REINFORCE leave-one-out estimator. We apply our method to challenging high-dimensional
  toy examples and for training variational autoencoders with binary latent variables.
  We show that our estimator can have lower variance compared to other state-of-the-art
  estimators. "
software: " https://github.com/thjashin/double-cv "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: titsias22a
month: 0
tex_title: " Double Control Variates for Gradient Estimation in Discrete Latent Variable
  Models "
firstpage: 6134
lastpage: 6151
page: 6134-6151
order: 6134
cycles: false
bibtex_author: Titsias, Michalis and Shi, Jiaxin
author:
- given: Michalis
  family: Titsias
- given: Jiaxin
  family: Shi
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/titsias22a/titsias22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
