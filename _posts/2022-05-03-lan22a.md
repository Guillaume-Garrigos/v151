---
title: " Model-free Policy Learning with Reward Gradients "
abstract: " Despite the increasing popularity of policy gradient methods, they are
  yet to be widely utilized in sample-scarce applications, such as robotics. The sample
  efficiency could be improved by making best usage of available information. As a
  key component in reinforcement learning, the reward function is usually devised
  carefully to guide the agent. Hence, the reward function is usually known, allowing
  access to not only scalar reward signals but also reward gradients. To benefit from
  reward gradients, previous works require the knowledge of environment dynamics,
  which are hard to obtain. In this work, we develop the Reward Policy Gradient estimator,
  a novel approach that integrates reward gradients without learning a model. Bypassing
  the model dynamics allows our estimator to achieve a better bias-variance trade-off,
  which results in a higher sample efficiency, as shown in the empirical analysis.
  Our method also boosts the performance of Proximal Policy Optimization on different
  MuJoCo control tasks. "
software: " https://github.com/qlan3/Explorer/tree/RPG "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lan22a
month: 0
tex_title: " Model-free Policy Learning with Reward Gradients "
firstpage: 4217
lastpage: 4234
page: 4217-4234
order: 4217
cycles: false
bibtex_author: Lan, Qingfeng and Tosatto, Samuele and Farrahi, Homayoon and Mahmood,
  Rupam
author:
- given: Qingfeng
  family: Lan
- given: Samuele
  family: Tosatto
- given: Homayoon
  family: Farrahi
- given: Rupam
  family: Mahmood
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/lan22a/lan22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
