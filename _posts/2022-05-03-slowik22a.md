---
title: " On Distributionally Robust Optimization and Data Rebalancing "
abstract: " Machine learning systems based on minimizing average error have been shown
  to perform inconsistently across notable subsets of the data, which is not exposed
  by a low average error for the entire dataset. Distributionally Robust Optimization
  (DRO) seemingly addresses this problem by minimizing the worst expected risk across
  subpopulations. We establish theoretical results that clarify the relation between
  DRO and the optimization of the same loss averaged on an adequately weighted training
  dataset. The results cover finite and infinite number of training distributions,
  as well as convex and non-convex loss functions. An implication of our results is
  that for each DRO problem there exists a data distribution such that learning this
  distribution is equivalent to solving the DRO problem. Yet, important problems that
  DRO seeks to address (for instance, adversarial robustness and fighting bias) cannot
  be reduced to finding the one ’unbiased’ dataset. Our discussion section addresses
  this important discrepancy. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: slowik22a
month: 0
tex_title: " On Distributionally Robust Optimization and Data Rebalancing "
firstpage: 1283
lastpage: 1297
page: 1283-1297
order: 1283
cycles: false
bibtex_author: S{\l}owik, Agnieszka and Bottou, Leon
author:
- given: Agnieszka
  family: Słowik
- given: Leon
  family: Bottou
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/slowik22a/slowik22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
