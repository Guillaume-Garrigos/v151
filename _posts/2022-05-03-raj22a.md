---
title: " Faster Rates, Adaptive Algorithms, and Finite-Time Bounds for Linear Composition
  Optimization and Gradient TD Learning "
abstract: " Gradient temporal difference (GTD) algorithms are provably convergent
  policy evaluation methods for off-policy reinforcement learning. Despite much progress,
  proper tuning of the stochastic approximation methods used to solve the resulting
  saddle point optimization problem requires the knowledge of several (unknown) problem-dependent
  parameters. In this paper we apply adaptive step-size tuning strategies to greatly
  reduce this dependence on prior knowledge, and provide algorithms with adaptive
  convergence guarantees. In addition, we use the underlying refined analysis technique
  to obtain new O(1/T) rates that do not depend on the strong-convexity parameter
  of the problem, and also apply to the Markov noise setting, as well as the unbounded
  i.i.d. noise setting. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: raj22a
month: 0
tex_title: " Faster Rates, Adaptive Algorithms, and Finite-Time Bounds for Linear
  Composition Optimization and Gradient TD Learning "
firstpage: 7176
lastpage: 7186
page: 7176-7186
order: 7176
cycles: false
bibtex_author: Raj, Anant and Joulani, Pooria and Gyorgy, Andras and Szepesvari, Csaba
author:
- given: Anant
  family: Raj
- given: Pooria
  family: Joulani
- given: Andras
  family: Gyorgy
- given: Csaba
  family: Szepesvari
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/raj22a/raj22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
