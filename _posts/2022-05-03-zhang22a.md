---
title: " A Class of Geometric Structures in Transfer Learning: Minimax Bounds and
  Optimality "
abstract: " We study the problem of transfer learning, observing that previous efforts
  to understand its information-theoretic limits do not fully exploit the geometric
  structure of the source and target domains. In contrast, our study first illustrates
  the benefits of incorporating a natural geometric structure within a linear regression
  model, which corresponds to the generalized eigenvalue problem formed by the Gram
  matrices of both domains. We next establish a finite-sample minimax lower bound,
  propose a refined model interpolation estimator that enjoys a matching upper bound,
  and then extend our framework to multiple source domains and generalized linear
  models. Surprisingly, as long as information is available on the distance between
  the source and target parameters, negative-transfer does not occur. Simulation studies
  show that our proposed interpolation estimator outperforms state-of-the-art transfer
  learning methods in both moderate- and high-dimensional settings. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang22a
month: 0
tex_title: " A Class of Geometric Structures in Transfer Learning: Minimax Bounds
  and Optimality "
firstpage: 3794
lastpage: 3820
page: 3794-3820
order: 3794
cycles: false
bibtex_author: Zhang, Xuhui and Blanchet, Jose and Ghosh, Soumyadip and Squillante,
  Mark S.
author:
- given: Xuhui
  family: Zhang
- given: Jose
  family: Blanchet
- given: Soumyadip
  family: Ghosh
- given: Mark S.
  family: Squillante
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/zhang22a/zhang22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
