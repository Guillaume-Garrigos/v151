---
title: " Marginalized Operators for Off-policy Reinforcement Learning "
abstract: " In this work, we propose marginalized operators, a new class of off-policy
  evaluation operators for reinforcement learning. Marginalized operators strictly
  generalize generic multi-step operators, such as Retrace, as special cases. Marginalized
  operators also suggest a form of sample-based estimates with potential variance
  reduction, compared to sample-based estimates of the original multi-step operators.
  We show that the estimates for marginalized operators can be computed in a scalable
  way, which also generalizes prior results on marginalized importance sampling as
  special cases. Finally, we empirically demonstrate that marginalized operators provide
  performance gains to off-policy evaluation problems and downstream policy optimization
  algorithms. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tang22a
month: 0
tex_title: " Marginalized Operators for Off-policy Reinforcement Learning "
firstpage: 655
lastpage: 679
page: 655-679
order: 655
cycles: false
bibtex_author: Tang, Yunhao and Rowland, Mark and Munos, Remi and Valko, Michal
author:
- given: Yunhao
  family: Tang
- given: Mark
  family: Rowland
- given: Remi
  family: Munos
- given: Michal
  family: Valko
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/tang22a/tang22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
