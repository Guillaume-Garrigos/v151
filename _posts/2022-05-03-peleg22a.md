---
title: " Metalearning Linear Bandits by Prior Update "
abstract: " Fully Bayesian approaches to sequential decision-making assume that problem
  parameters are generated from a known prior. In practice, such information is often
  lacking. This problem is exacerbated in setups with partial information, where a
  misspecified prior may lead to poor exploration and performance. In this work we
  prove, in the context of stochastic linear bandits and Gaussian priors, that as
  long as the prior is sufficiently close to the true prior, the performance of the
  applied algorithm is close to that of the algorithm that uses the true prior. Furthermore,
  we address the task of learning the prior through metalearning, where a learner
  updates her estimate of the prior across multiple task instances in order to improve
  performance on future tasks. We provide an algorithm and regret bounds, demonstrate
  its effectiveness in comparison to an algorithm that knows the correct prior, and
  support our theoretical results empirically. Our theoretical results hold for a
  broad class of algorithms, including Thompson Sampling and Information Directed
  Sampling. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: peleg22a
month: 0
tex_title: " Metalearning Linear Bandits by Prior Update "
firstpage: 2885
lastpage: 2926
page: 2885-2926
order: 2885
cycles: false
bibtex_author: Peleg, Amit and Pearl, Naama and Meir, Ron
author:
- given: Amit
  family: Peleg
- given: Naama
  family: Pearl
- given: Ron
  family: Meir
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/peleg22a/peleg22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
