---
title: " Optimal estimation of Gaussian DAG models "
abstract: " We study the optimal sample complexity of learning a Gaussian directed
  acyclic graph (DAG) from observational data. Our main results establish the minimax
  optimal sample complexity for learning the structure of a linear Gaussian DAG model
  in two settings of interest: 1) Under equal variances without knowledge of the true
  ordering, and 2) For general linear models given knowledge of the ordering. In both
  cases the sample complexity is $n\\asymp q\\log(d/q)$, where $q$ is the maximum
  number of parents and $d$ is the number of nodes. We further make comparisons with
  the classical problem of learning (undirected) Gaussian graphical models, showing
  that under the equal variance assumption, these two problems share the same optimal
  sample complexity. In other words, at least for Gaussian models with equal error
  variances, learning a directed graphical model is statistically no more difficult
  than learning an undirected graphical model. Our results also extend to more general
  identification assumptions as well as subgaussian errors. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gao22a
month: 0
tex_title: " Optimal estimation of Gaussian DAG models "
firstpage: 8738
lastpage: 8757
page: 8738-8757
order: 8738
cycles: false
bibtex_author: Gao, Ming and Ming Tai, Wai and Aragam, Bryon
author:
- given: Ming
  family: Gao
- given: Wai
  family: Ming Tai
- given: Bryon
  family: Aragam
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/gao22a/gao22a.pdf
extras:
- label: Supplementary ZIP
  link: https://proceedings.mlr.press/v151/gao22a/gao22a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
