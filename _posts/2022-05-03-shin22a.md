---
title: " Multi-armed Bandit Algorithm against Strategic Replication "
abstract: " We consider a multi-armed bandit problem in which a set of arms is registered
  by each agent, and the agent receives reward when its arm is selected. An agent
  might strategically submit more arms with replications, which can bring more reward
  by abusing the bandit algorithmâ€™s exploration-exploitation balance. Our analysis
  reveals that a standard algorithm indeed fails at preventing replication and suffers
  from linear regret in time $T$. We aim to design a bandit algorithm which demotivates
  replications and also achieves a small cumulative regret. We devise Hierarchical
  UCB (H-UCB) of replication-proof, which has $O(\\ln T)$-regret under any equilibrium.
  We further propose Robust Hierarchical UCB (RH-UCB) which has a sublinear regret
  even in a realistic scenario with irrational agents replicating careless. We verify
  our theoretical findings through numerical experiments. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shin22a
month: 0
tex_title: " Multi-armed Bandit Algorithm against Strategic Replication "
firstpage: 403
lastpage: 431
page: 403-431
order: 403
cycles: false
bibtex_author: Shin, Suho and Lee, Seungjoon and Ok, Jungseul
author:
- given: Suho
  family: Shin
- given: Seungjoon
  family: Lee
- given: Jungseul
  family: Ok
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/shin22a/shin22a.pdf
extras:
- label: Supplementary ZIP
  link: https://proceedings.mlr.press/v151/shin22a/shin22a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
