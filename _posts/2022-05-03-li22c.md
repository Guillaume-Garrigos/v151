---
title: " State Dependent Performative Prediction with Stochastic Approximation "
abstract: " This paper studies the performative prediction problem which optimizes
  a stochastic loss function with data distribution that depends on the decision variable.
  We consider a setting where the agent(s) provides samples adapted to both the learner’s
  and agent’s previous states. The samples are then used by the learner to update
  his/her state to optimize a loss function. Such closed loop update dynamics is studied
  as a state dependent stochastic approximation (SA) algorithm, which is shown to
  find a fixed point known as the performative stable solution. Our setting captures
  the unforgetful nature and reliance on past experiences of agents. Our contributions
  are three-fold. First, we present a framework for state dependent performative prediction
  with biased stochastic gradients driven by a controlled Markov chain whose transition
  probability depends on the learner’s state. Second, we present a new finite-time
  performance analysis of the SA algorithm. We show that the expected squared distance
  to the performative stable solution decreases as O(1/k), where k is the iteration
  number. Third, numerical experiments verify our findings. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li22c
month: 0
tex_title: " State Dependent Performative Prediction with Stochastic Approximation "
firstpage: 3164
lastpage: 3186
page: 3164-3186
order: 3164
cycles: false
bibtex_author: Li, Qiang and Wai, Hoi-To
author:
- given: Qiang
  family: Li
- given: Hoi-To
  family: Wai
date: 2022-05-03
address:
container-title: Proceedings of The 25th International Conference on Artificial Intelligence
  and Statistics
volume: '151'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 5
  - 3
pdf: https://proceedings.mlr.press/v151/li22c/li22c.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
